
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"\rI’m a PhD student advised by Prof.Kwanghoon Sohn in the Department of Electrical and Electronic Engineering at Yonsei University, South Korea. My research interests include computer vision, video understanding, and vision-language models.\n","date":1677542400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677542400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a PhD student advised by Prof.Kwanghoon Sohn in the Department of Electrical and Electronic Engineering at Yonsei University, South Korea. My research interests include computer vision, video understanding, and vision-language models.","tags":null,"title":"Jungin Park","type":"authors"},{"authors":null,"categories":null,"content":"\r","date":1689638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689638400,"objectID":"21347c7d0a801e5f98f3fdfa9ecc13f7","permalink":"https://park-jungin.github.io/post/iccv2023/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/iccv2023/","section":"post","summary":"Our paper on video grounding was accepted to **ICCV** 2023.","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"\r","date":1677542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677542400,"objectID":"aa7d5409f1fa20125c5c9062f861b055","permalink":"https://park-jungin.github.io/post/cvpr2023/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/cvpr2023/","section":"post","summary":"Our two paper were accepted to **CVPR** 2023.","tags":null,"title":"","type":"post"},{"authors":["Jungin Park","Jiyoung Lee","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1677542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677542400,"objectID":"6fd2c67cf55fd6fe70521144bc64e633","permalink":"https://park-jungin.github.io/publication/cvpr2023-2/","publishdate":"2023-02-28T00:00:00Z","relpermalink":"/publication/cvpr2023-2/","section":"publication","summary":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023","tags":[],"title":"Dual-path Adaptation from Image to Video Transformers","type":"publication"},{"authors":["Minsu Kim","Seungryong Kim","Jungin Park","Seongheon Park","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1677542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677542400,"objectID":"2fcf4b569b4a0160b2851f57f39b3ca5","permalink":"https://park-jungin.github.io/publication/cvpr2023-1/","publishdate":"2023-02-28T00:00:00Z","relpermalink":"/publication/cvpr2023-1/","section":"publication","summary":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023","tags":[],"title":"PartMix: Regularization Strategy to Learn Part Discovery for Visible-Infrared Person Re-identification","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1665619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665619200,"objectID":"f9721e3b64a7e9ede92715ba99bb3c8c","permalink":"https://park-jungin.github.io/post/wacv2023/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/wacv2023/","section":"post","summary":"Our paper on zero-shot video grounding was accepted to **WACV** 2023.","tags":null,"title":"","type":"post"},{"authors":["Dahye Kim","Jungin Park","Jiyoung Lee","Seongheon Park","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1665619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665619200,"objectID":"8f1e85d666ed559c2216fb12d5c3fd48","permalink":"https://park-jungin.github.io/publication/wacv2023/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/publication/wacv2023/","section":"publication","summary":"IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023","tags":[],"title":"Language-free Training for Zero-shot Video Grounding","type":"publication"},{"authors":["Kwonyoung Kim","Jungin Park","Jiyoung Lee","Dongbo Min","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1657670400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657670400,"objectID":"b36f98c2d8d63e0312826ae9a389f4c9","permalink":"https://park-jungin.github.io/publication/eccv2022/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/publication/eccv2022/","section":"publication","summary":"European Conference on Computer Vision (ECCV) 2022","tags":[],"title":"PointFix: Learning to Fix Domian Bias for Robust Online Stereo Adaptation","type":"publication"},{"authors":null,"categories":null,"content":"\r","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"2299dae26e584c0dce6242e8ad2bc3c8","permalink":"https://park-jungin.github.io/post/eccv2022/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/eccv2022/","section":"post","summary":"Our paper on online stereo adaptation was accepted to **ECCV** 2022.","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"Research on artificial intelligence technology that can mimic various human abilities by using image/video, voice/audio, and text/natural language, which are the basis of artificial intelligence.\nComplex and comprehensive scene understanding using multimodal signals, user understanding, virtual space-time synthesis technology, and development of a general-purpose social artificial intelligence system through the integration of these technologies.\n","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"e9f2758a8cec6fe970889b4e8ea07727","permalink":"https://park-jungin.github.io/project/project4/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/project/project4/","section":"project","summary":"Funded by Yonsei University-Yonsei signature research cluster.","tags":["Deep Learning"],"title":"Development of Multimodal-based General-purpose Social Artificial Intelligence Technology","type":"project"},{"authors":["Jin Kim","Jiyoung Lee","Jungin Park","Dongbo Min","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"e3e3fe90d584ae47549dc01ab0e5ff30","permalink":"https://park-jungin.github.io/publication/cvpr2022-2/","publishdate":"2022-06-22T00:00:00Z","relpermalink":"/publication/cvpr2022-2/","section":"publication","summary":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022","tags":[],"title":"Pin the Memory: Learning to Generalize Semantic Segmentation","type":"publication"},{"authors":["Jungin Park","Jiyoung Lee","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"735b3a0805a52c74d1b2d3dcb8b9382c","permalink":"https://park-jungin.github.io/publication/cvpr2022-1/","publishdate":"2022-06-22T00:00:00Z","relpermalink":"/publication/cvpr2022-1/","section":"publication","summary":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022","tags":[],"title":"Probabilistic Representations for Video Contrastive Learning","type":"publication"},{"authors":["Jin Kim","Jiyoung Lee","Jungin Park","Dongbo Min","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1619136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619136000,"objectID":"0582bd5bd34b051f7e2f01f2c3cbcff9","permalink":"https://park-jungin.github.io/publication/icip2021/","publishdate":"2021-09-21T00:00:00Z","relpermalink":"/publication/icip2021/","section":"publication","summary":"IEEE International Conference on Image Processing (ICIP) 2021","tags":[],"title":"Self-Balanced Learning for Domain Generalization","type":"publication"},{"authors":["Jungin Park","Jiyoung Lee","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"96c130abf8fb5e9c540db2b6a9ac7152","permalink":"https://park-jungin.github.io/publication/cvpr2021/","publishdate":"2021-06-22T00:00:00Z","relpermalink":"/publication/cvpr2021/","section":"publication","summary":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2021","tags":[],"title":"Bridge to Answer: Structure-aware Graph Interaction Network for Video Question Answering","type":"publication"},{"authors":null,"categories":null,"content":"Developing source technology for complext scene understanding and future prediction through artificial intelligence neural networks.\nIntegrating complementary information in multiple ways through convergence between multimodal data.\nDescribing human social intelligence to develop complex relationship reasoning skills bewteen multiple objects and surrounding environments through learning of a social AI.\n","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"68fe1e900090392e3d2a97574964bc5a","permalink":"https://park-jungin.github.io/project/project3/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/project/project3/","section":"project","summary":"Funded by Ministry of science, mid-level research","tags":["Deep Learning"],"title":"Development of Complex Situational Awareness and Prediction Technology through Multi-modal Data Fusion and Social Artificial Intelligence","type":"project"},{"authors":["Minsu Kim","Sunghun Joung","Seungryong Kim","Jungin Park","Ig-Jae Kim","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"48ddb5df06a3d7df7d5a33e736515385","permalink":"https://park-jungin.github.io/publication/aaai2021/","publishdate":"2021-02-04T00:00:00Z","relpermalink":"/publication/aaai2021/","section":"publication","summary":"AAAI Conference on Artificial Intelligence (AAAI) 2021","tags":[],"title":"Cross-Domain Grouping and Alignment for Domain Adaptive Semantic Segmentation","type":"publication"},{"authors":["Jungin Park","Jiyoung Lee","Ig-Jae Kim","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1594598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594598400,"objectID":"4d6fdf4697c10cbcfc4820b1b90bdbe3","permalink":"https://park-jungin.github.io/publication/eccv2020/","publishdate":"2020-10-05T00:00:00Z","relpermalink":"/publication/eccv2020/","section":"publication","summary":"European Conference on Computer Vision (ECCV) 2020","tags":[],"title":"SumGraph: Video Summarization via Recursive Graph Modeling","type":"publication"},{"authors":null,"categories":null,"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"5302252e8f3539312931c7276cda35e3","permalink":"https://park-jungin.github.io/project/project2/","publishdate":"2020-03-01T00:00:00Z","relpermalink":"/project/project2/","section":"project","summary":"Funded by Institue of information \u0026 communication technology.","tags":["Deep Learning"],"title":"Development of AI Technology for Continuously Improves according to the Changing Situation in the Real World","type":"project"},{"authors":[],"categories":null,"content":"\r","date":1572480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572480000,"objectID":"85be463444fcbcd9339c785aeec4958c","permalink":"https://park-jungin.github.io/talk/2nd-award/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2nd-award/","section":"event","summary":"Workshop on Frontiers of Electical Engineering (FREE) 2019","tags":[],"title":"2nd Award","type":"event"},{"authors":["Jiyoung Lee","Seungryong Kim","Sunok Kim","Jungin Park","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1562976000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562976000,"objectID":"5411330181b10edecc9a1290f8caab9a","permalink":"https://park-jungin.github.io/publication/iccv2019/","publishdate":"2019-10-05T00:00:00Z","relpermalink":"/publication/iccv2019/","section":"publication","summary":"IEEE/CVF International Conference on Computer Vision (ICCV) 2019","tags":[],"title":"Context-Aware Emotion Recognition Networks","type":"publication"},{"authors":["Jungin Park","Jiyoung Lee","Sangryul Jeon","Seungryong Kim","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1562976000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562976000,"objectID":"963bbe7df2392bc40e7ad7ee98c04e6a","permalink":"https://park-jungin.github.io/publication/iccvw2019/","publishdate":"2019-10-05T00:00:00Z","relpermalink":"/publication/iccvw2019/","section":"publication","summary":"IEEE/CVF International Conference on Computer Vision Workshop (ICCVW) 2019","tags":[],"title":"Video Summarization by Learning Relationships between Action and Scene","type":"publication"},{"authors":["Jungin Park","Jiyoung Lee","Sangryul Jeon","Seungryong Kim","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1555977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555977600,"objectID":"31a4531b4f5809f5ee030cc38c2824cc","permalink":"https://park-jungin.github.io/publication/icip2019/","publishdate":"2019-09-21T00:00:00Z","relpermalink":"/publication/icip2019/","section":"publication","summary":"IEEE International Conference on Image Processing (ICIP) 2019","tags":[],"title":"Graph Regularization Network with Semantic Affinity for Weakly-supervised Temporal Action Localization","type":"publication"},{"authors":["Jungin Park"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"397468ca9e573e23f848aa93199f3422","permalink":"https://park-jungin.github.io/publication_unused/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication_unused/preprint/","section":"publication_unused","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication_unused"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://park-jungin.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Jungin Park","Sangryul Jeon","Seungryong Kim","Jiyoung Lee","Sunok Kim","Kwanghoon Sohn"],"categories":null,"content":"\r","date":1531440000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531440000,"objectID":"3179d9055fe416adc28a19b2bed3388b","permalink":"https://park-jungin.github.io/publication/mmw2018/","publishdate":"2018-10-05T00:00:00Z","relpermalink":"/publication/mmw2018/","section":"publication","summary":"ACM Multimedia Workshop (MMW) 2018","tags":[],"title":"Learning to Detect, Associate, and Recognize Human Actions and Surrounding Scenes in Untrimmed Videos","type":"publication"},{"authors":null,"categories":null,"content":"Developing artificial intelligence/machine learning source technology through future situation prediction research through human-like comprehensive video understanding.\nComprehensive video understanding includes contextual information through correlation analysis between human emotion/action/surrounding scene.\nDevelopment of emotion recognition technology through video-based interaction of emotion/action/environment.\nDevelopment of human-centric comprehensive video scene analysis and action recognition technology.\nDevelopment of environmental change prediction technology through comprehensive situational recognition.\n","date":1519862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519862400,"objectID":"9b74b6d80c74c11210b876d3c28bd186","permalink":"https://park-jungin.github.io/project/project1/","publishdate":"2018-03-01T00:00:00Z","relpermalink":"/project/project1/","section":"project","summary":"Funded by Ministry of science, ICT and future plannning.","tags":["Deep Learning"],"title":"Fundamental Research on Vision Algorithms for Comprehensive and Thorough Video Understanding","type":"project"},{"authors":["Jungin Park","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"f866ec4ef71755ec2aba2a8ec8b45327","permalink":"https://park-jungin.github.io/publication_unused/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication_unused/journal-article/","section":"publication_unused","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication_unused"}]